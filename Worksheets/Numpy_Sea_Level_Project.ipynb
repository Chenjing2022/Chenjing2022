{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numpy Sea-Level-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chenjing2022/Chenjing2022-Data-Analysis-and-Python/blob/main/Worksheets/Numpy_Sea_Level_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference link: \n",
        "\n",
        "https://www.freecodecamp.org/learn/data-analysis-with-python/data-analysis-with-python-projects/sea-level-predictor"
      ],
      "metadata": {
        "id": "Sya8dPB-JlWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using numpy to look for a correlation between time data and sea level rise\n",
        "---\n",
        "\n",
        "### Data Source\n",
        "Global Average Absolute Sea Level Change, 1880-2014 from the US Environmental Protection Agency using data from CSIRO, 2015; NOAA, 2015.\n",
        "https://datahub.io/core/sea-level-rise\n",
        "\n",
        "The data describes annual sea levels from 1880 to 2013.  Measures are adjusted using two standards: Commonwealth Scientific and Industrial Research Organisation(CSIRO) and National Oceanic and Atmospheric Administration (NOAA)  \n",
        "\n",
        "Raw Data file:  https://raw.githubusercontent.com/freeCodeCamp/boilerplate-sea-level-predictor/master/epa-sea-level.csv\n",
        "\n",
        "For this exercise:\n",
        "*  import the pandas library\n",
        "*  import the numpy library\n",
        "*  read the csv dataset containing data on sea-levels from the year 1880 to 2013 into a dataframe (df)\n",
        "*  use df.head() and df.info() to inspect the data and the column data types\n",
        "\n"
      ],
      "metadata": {
        "id": "jBYNdCdQ9_cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = \"https://raw.githubusercontent.com/freeCodeCamp/boilerplate-sea-level-predictor/master/epa-sea-level.csv\"\n",
        "sea_levels = pd.read_csv(url)\n",
        "\n",
        "\n",
        "def get_summary():\n",
        "  # add code below which prints the first 5 rows of the dataset, the info and the numerical summary\n",
        "  #return sea_levels.head(), sea_levels.info()\n",
        "  print(sea_levels.head())\n",
        "  print(sea_levels.info())\n",
        "get_summary()"
      ],
      "metadata": {
        "id": "r1XUCWHV_Cj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9941a17-dee5-4944-fd48-c9d6b90e2020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year  CSIRO Adjusted Sea Level  ...  Upper Error Bound  NOAA Adjusted Sea Level\n",
            "0  1880                  0.000000  ...           0.952756                      NaN\n",
            "1  1881                  0.220472  ...           1.173228                      NaN\n",
            "2  1882                 -0.440945  ...           0.464567                      NaN\n",
            "3  1883                 -0.232283  ...           0.665354                      NaN\n",
            "4  1884                  0.590551  ...           1.464567                      NaN\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 134 entries, 0 to 133\n",
            "Data columns (total 5 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Year                      134 non-null    int64  \n",
            " 1   CSIRO Adjusted Sea Level  134 non-null    float64\n",
            " 2   Lower Error Bound         134 non-null    float64\n",
            " 3   Upper Error Bound         134 non-null    float64\n",
            " 4   NOAA Adjusted Sea Level   21 non-null     float64\n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 5.4 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then\n",
        "---\n",
        "1.  Calculate some statistics on the level array, eg:\n",
        "*  mean\n",
        "*  standard deviation\n",
        "*  total \n",
        "\n",
        "2.  Use the fact that the arrays are aligned (e.g. the first number in the level array is linked to the first year in the year array and display:\n",
        "\n",
        "*  the year with the biggest rise in level\n",
        "*  the year with the lowest rise in level\n",
        "\n",
        "*(**Hint**:  to do this you can use a new numpy function np.where() )*\n",
        " ```\n",
        "np.where(array == value_to_find)\n",
        "```\n",
        "*There is some reference material [here](https://thispointer.com/find-the-index-of-a-value-in-numpy-array/)*\n",
        "\n",
        "**Note**: ```np.where(...)``` will return a tuple containing all indexes where that value was found.  You can print all, or you can print the first value (it is likely that there will only be one in this case) using [0][0].  *With the correct code you should get an answer of 2012*\n",
        "\n",
        "\n",
        "3.  Calculate the Pearson product-moment correlation coefficient between year and the rise in sea level.  (*Expected output:  0.98 when rounded to 2 decimal places*)"
      ],
      "metadata": {
        "id": "3cf1YPgnBSc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VWUtmK4YhoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4e9614-4cc5-4740-8f1b-58cc6e215063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean 3.650340811880598 Std 2.476399631426498 Total 489.1456687920001 Highest sea level 9.326771643999999 Lowest sea level -0.440944881\n",
            "2012\n",
            "1882\n",
            "[[1.         0.98475713]\n",
            " [0.98475713 1.        ]]\n",
            "0.98\n"
          ]
        }
      ],
      "source": [
        "def get_levels(): \n",
        "  year = sea_levels[\"Year\"].to_numpy(np.int64)\n",
        "  level =sea_levels[\"CSIRO Adjusted Sea Level\"].to_numpy(np.float64) # adding CSiro ajusted colum\n",
        "\n",
        "#Calculate  mean, standard deviation, total\n",
        "  avg_level = level.mean()\n",
        "  std = level.std()\n",
        "  sum = level.sum()\n",
        "  max = level.max()# highest sea level \n",
        "  min = level.min() # lowest sea level\n",
        "  print(\"Mean\",avg_level, \"Std\", std, \"Total\",sum, \"Highest sea level\",max, \"Lowest sea level\",min)\n",
        "\n",
        "  #the year with the biggest rise in level\n",
        "  higgest_sea_rise_year = np.where(level == max)[0][0]\n",
        "  #the year with the lowest rise in level\n",
        "  lowest_sea_rise_year = np.where(sea_levels == min)[0][0]\n",
        "  print(year[higgest_sea_rise_year])\n",
        "  print(year[lowest_sea_rise_year])\n",
        "\n",
        "  #Calculate correlation coefficien\n",
        "  coeff =np. corrcoef(year,level)\n",
        "  print(coeff)\n",
        "  print(round(coeff[0][1],2))\n",
        "  \n",
        "get_levels()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "Your answer: \n",
        "\n",
        "Importing libraries such as pandas, numpy for extracting the dataset. \n",
        "\n",
        "Read the csv dataset containing data on sea-levels from the year 1880 to 2013 into a dataframe (df)\n",
        "\n",
        "Used df.head() and df.info() to inspect the data and the column data types\n",
        "\n",
        "Used numpy function *np.where() *to calculate some statistics on the sea level array such as: \n",
        "\n",
        "*   mean\n",
        "*   standard deviation \n",
        "*   total\n",
        "*   the year with the biggest rise in level\n",
        "*   the year with the lowest rise in level\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "Your answer:  Calculate correlation coefficien part and had help from Karen she showed us how to round up to 2 decimal place. "
      ]
    }
  ]
}